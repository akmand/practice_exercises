{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercise: Scikit-Learn 2\n",
    "### Feature Selection and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "As in the [SK2 Tutorial](https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-2-feature-selection-and-ranking/), the goal of this practice notebook is to illustrate how you can perform feature selection (FS) and ranking using the relevant methods within `Scikit-Learn`. You will be using the cleaned \"income data\" from previous data preparation practices you will take a cross-validation (CV) approach. \n",
    "\n",
    "In the previous practices, you cleaned and transformed the raw `income data` and renamed the `income` column as `target` (with high income being the positive class). Including `target`, the cleaned data consists of 42 columns and 45,222 rows. Each column is numeric and between 0 and 1.\n",
    "\n",
    "For FS methods other than the ones illustrated here, please refer to the official `Scikit-Learn` documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning: The Art and The Science\n",
    "\n",
    "If you notice things in our practice exercises that are different from those in the corresponding tutorials, it's OK. There are usually multiple ways of doing the right thing in ML, and more importantly, always keep in mind that machine learning is as much **art** as it is **science**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- For all the questions below, you will use **stratified 5-fold cross-validation with no repetitions** and set the random state to 999 when applicable. \n",
    "- As the wrapper (that is, the intended classifier), you will use a decision tree with a `max_depth` of 5. Don't forget to set the `random_state` so that your results do not change from run to run.\n",
    "- For ease of computation, you will first randomly sample 5,000 rows from this dataset. \n",
    "- You will then split this sample into two equal-sized datasets.\n",
    "- You will use the first set for **training**: you will find the best 10-features using different methods using this train data. \n",
    "- You will use the second set for **testing**: you will perform cross-validation in a paired fashion using the test data and then you will compare the results using a paired t-test.\n",
    "- For scoring, you will use AUC, that is, \"area under the ROC curve\". \n",
    "\n",
    "**Hint:** For a list of scorers as a **string** that you can pass into `cross_val_score()` or `GridSearchCV()` methods, please try this:\n",
    "```Python\n",
    "from sklearn import metrics \n",
    "metrics.SCORERS.keys()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Bookkeeping\n",
    "\n",
    "- Define a variable called `num_samples` and set it to 5000. You will use this variable when sampling a smaller subset of the full set of instances.\n",
    "- Define a variable called `num_features` and set it to 10. You will perform all feature selection tasks by making use of this `num_features` variable.\n",
    "- Define a variable called `scoring_metric` and set it to to `'roc_auc'`. You will set `scoring` option in all `cross_val_score()` functions to this `scoring_metric` variable.\n",
    "- Define an object called `clf` and set its value to `DecisionTreeClassifier(max_depth=5, random_state=999)`. You will use this classifier as your wrapper when comparing performance of feature selection (FS) methods.\n",
    "\n",
    "You can achieve these by running the code chunk below:\n",
    "```Python\n",
    "import numpy as np\n",
    "num_samples = 5000\n",
    "num_features = 10\n",
    "scoring_metric = 'roc_auc'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=999)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 0: Modeling Preparation\n",
    "\n",
    "- Read in the clean data `us_census_income_data_clean_encoded.csv` on GitHub [here](https://github.com/akmand/datasets). \n",
    "- Randomly sample the rows.\n",
    "- Split the sampled data as 50% training set and the remaining 50% test set using a random seed of 999. \n",
    "- Remember to separate `target` during the splitting process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Assess the cross-validated performance of your DT classifier using the **test** data with all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Select the top 10 features via the **F-Score** method using the **train** data.\n",
    "- Evaluate the cross-validated performance of these features using your DT classifier on the **test** data.\n",
    "\n",
    "**NOTE:** For this particular dataset, the F-Score will be \"NaN\" for one of the features due to some technical reasons (related to the nature of the F-distribution). For this reason, when you pass the `fs_fit_fscore.scores_` object in to the `np.argsort()` function, you will need to apply the `np.nan_to_num()` function first. This way, you will convert that \"NaN\" value to zero for a correct result. Specifically, you will need the following line:\n",
    "```Python\n",
    "fs_indices_fscore = np.argsort(np.nan_to_num(fs_fit_fscore.scores_))[::-1][0:num_features]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "- Select the top 10 features using the **Mutual Information** method using the **train** data.\n",
    "- Evaluate the cross-validated performance of these features using your DT classifier on the **test** data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "- Select the top 10 features using the **Random Forest Importance** method (with `random_state=999`) with `n_estimators=100` using the **train** data.\n",
    "- Evaluate the cross-validated performance of these features using your DT classifier on the **test** data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Conduct 3 paired t-tests at a 95% significance level: the cross-validated performance with full set of features (using the **test** data) vs. each one of the three FS methods (evaluated again on the **test** data). \n",
    "\n",
    "But first remind yourself the performances of the FS methods by printing the 4 respective `cv_perf_?` variables.\n",
    "\n",
    "Comment on performance of which FS method(s) is (are) statistically different from that of the full set of features. Does FS seem to result in any meaningful dimensionality reduction in this particular case?\n",
    "\n",
    "**Hint:** Any p-value smaller than 0.05 indicates a statistically different result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Re-run your entire notebook with different combinations of different settings and see for yourself if FS is still meaningful. Some suggested changes are as follows:\n",
    "- Change `num_samples` to 10000 or 20000.\n",
    "- Change `num_features` to 5 or 20.\n",
    "- Change `scoring_metric` to 'accuracy' or 'f1'.\n",
    "- Change `max_depth` in DT to 3 or 10.\n",
    "- Try different wrappers, such as KNN with different $k$ and $p$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
