{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercise: Scikit-Learn 2\n",
    "### Feature Selection and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "As in the [SK2 Tutorial](https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-2-feature-selection-and-ranking/), the goal of this practice notebook is to illustrate how you can perform feature selection (FS) and ranking using the relevant methods within `Scikit-Learn`. You will be using the cleaned \"income data\" from previous data preparation practices you will take a cross-validation (CV) approach. \n",
    "\n",
    "In the previous practices, you cleaned and transformed the raw `income data` and renamed the `income` column as `target` (with high income being the positive class). Including `target`, the cleaned data consists of 42 columns and 45,222 rows. Each column is numeric and between 0 and 1.\n",
    "\n",
    "For FS methods other than the ones illustrated here, please refer to the official `Scikit-Learn` documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning: The Art and The Science\n",
    "\n",
    "If you notice things in our practice exercises that are different from those in the corresponding tutorials, it's OK. There are usually multiple ways of doing the right thing in ML, and more importantly, always keep in mind that machine learning is as much **art** as it is **science**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- For all the questions below, you will use **stratified 5-fold cross-validation with no repetitions** and set the random state to 999 when applicable. \n",
    "- As the wrapper (that is, the intended classifier), you will use a decision tree with a `max_depth` of 5. Don't forget to set the `random_state` so that your results do not change from run to run.\n",
    "- For ease of computation, you will first randomly sample 5,000 rows from this dataset. \n",
    "- You will then split this sample into two equal-sized datasets.\n",
    "- You will use the first set for **training**: you will find the best 10-features using different methods using this train data. \n",
    "- You will use the second set for **testing**: you will perform cross-validation in a paired fashion using the test data and then you will compare the results using a paired t-test.\n",
    "- For scoring, you will use AUC, that is, \"area under the ROC curve\". \n",
    "\n",
    "**Hint:** For a list of scorers as a **string** that you can pass into `cross_val_score()` or `GridSearchCV()` methods, please try this:\n",
    "```Python\n",
    "from sklearn import metrics \n",
    "metrics.SCORERS.keys()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Bookkeeping\n",
    "\n",
    "- Define a variable called `num_samples` and set it to 5000. You will use this variable when sampling a smaller subset of the full set of instances.\n",
    "- Define a variable called `num_features` and set it to 10. You will perform all feature selection tasks by making use of this `num_features` variable.\n",
    "- Define a variable called `scoring_metric` and set it to to `'roc_auc'`. You will set `scoring` option in all `cross_val_score()` functions to this `scoring_metric` variable.\n",
    "- Define an object called `clf` and set its value to `DecisionTreeClassifier(max_depth=5, random_state=999)`. You will use this classifier as your wrapper when comparing performance of feature selection (FS) methods.\n",
    "\n",
    "You can achieve these by running the code chunk below:\n",
    "```Python\n",
    "import numpy as np\n",
    "num_samples = 5000\n",
    "num_features = 10\n",
    "scoring_metric = 'roc_auc'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=999)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_samples = 5000\n",
    "num_features = 10\n",
    "scoring_metric = 'roc_auc'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 0: Modeling Preparation\n",
    "\n",
    "- Read in the clean data `us_census_income_data_clean_encoded.csv` on GitHub [here](https://github.com/akmand/datasets). \n",
    "- Randomly sample the rows.\n",
    "- Split the sampled data as 50% training set and the remaining 50% test set using a random seed of 999. \n",
    "- Remember to separate `target` during the splitting process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python38\\lib\\site-packages\\urllib3\\connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45222, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>capital</th>\n",
       "      <th>workclass_federal_gov</th>\n",
       "      <th>workclass_local_gov</th>\n",
       "      <th>workclass_private</th>\n",
       "      <th>workclass_self_emp_inc</th>\n",
       "      <th>workclass_self_emp_not_inc</th>\n",
       "      <th>workclass_state_gov</th>\n",
       "      <th>workclass_without_pay</th>\n",
       "      <th>marital_status_divorced</th>\n",
       "      <th>marital_status_married_af_spouse</th>\n",
       "      <th>marital_status_married_civ_spouse</th>\n",
       "      <th>marital_status_married_spouse_absent</th>\n",
       "      <th>marital_status_never_married</th>\n",
       "      <th>marital_status_separated</th>\n",
       "      <th>marital_status_widowed</th>\n",
       "      <th>occupation_adm_clerical</th>\n",
       "      <th>occupation_armed_forces</th>\n",
       "      <th>occupation_craft_repair</th>\n",
       "      <th>occupation_exec_managerial</th>\n",
       "      <th>occupation_farming_fishing</th>\n",
       "      <th>occupation_handlers_cleaners</th>\n",
       "      <th>occupation_machine_op_inspct</th>\n",
       "      <th>occupation_other_service</th>\n",
       "      <th>occupation_priv_house_serv</th>\n",
       "      <th>occupation_prof_specialty</th>\n",
       "      <th>occupation_protective_serv</th>\n",
       "      <th>occupation_sales</th>\n",
       "      <th>occupation_tech_support</th>\n",
       "      <th>occupation_transport_moving</th>\n",
       "      <th>relationship_husband</th>\n",
       "      <th>relationship_not_in_family</th>\n",
       "      <th>relationship_other_relative</th>\n",
       "      <th>relationship_own_child</th>\n",
       "      <th>relationship_unmarried</th>\n",
       "      <th>relationship_wife</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288</td>\n",
       "      <td>0.533</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  education_num  race  gender  hours_per_week  native_country  \\\n",
       "0  0.301          0.800     1       1           0.398               1   \n",
       "1  0.452          0.800     1       1           0.122               1   \n",
       "2  0.288          0.533     1       1           0.398               1   \n",
       "3  0.493          0.400     0       1           0.398               1   \n",
       "4  0.151          0.800     0       0           0.398               0   \n",
       "\n",
       "   capital  workclass_federal_gov  workclass_local_gov  workclass_private  \\\n",
       "0    0.063                      0                    0                  0   \n",
       "1    0.042                      0                    0                  0   \n",
       "2    0.042                      0                    0                  1   \n",
       "3    0.042                      0                    0                  1   \n",
       "4    0.042                      0                    0                  1   \n",
       "\n",
       "   workclass_self_emp_inc  workclass_self_emp_not_inc  workclass_state_gov  \\\n",
       "0                       0                           0                    1   \n",
       "1                       0                           1                    0   \n",
       "2                       0                           0                    0   \n",
       "3                       0                           0                    0   \n",
       "4                       0                           0                    0   \n",
       "\n",
       "   workclass_without_pay  marital_status_divorced  \\\n",
       "0                      0                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        1   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   marital_status_married_af_spouse  marital_status_married_civ_spouse  \\\n",
       "0                                 0                                  0   \n",
       "1                                 0                                  1   \n",
       "2                                 0                                  0   \n",
       "3                                 0                                  1   \n",
       "4                                 0                                  1   \n",
       "\n",
       "   marital_status_married_spouse_absent  marital_status_never_married  \\\n",
       "0                                     0                             1   \n",
       "1                                     0                             0   \n",
       "2                                     0                             0   \n",
       "3                                     0                             0   \n",
       "4                                     0                             0   \n",
       "\n",
       "   marital_status_separated  marital_status_widowed  occupation_adm_clerical  \\\n",
       "0                         0                       0                        1   \n",
       "1                         0                       0                        0   \n",
       "2                         0                       0                        0   \n",
       "3                         0                       0                        0   \n",
       "4                         0                       0                        0   \n",
       "\n",
       "   occupation_armed_forces  occupation_craft_repair  \\\n",
       "0                        0                        0   \n",
       "1                        0                        0   \n",
       "2                        0                        0   \n",
       "3                        0                        0   \n",
       "4                        0                        0   \n",
       "\n",
       "   occupation_exec_managerial  occupation_farming_fishing  \\\n",
       "0                           0                           0   \n",
       "1                           1                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   occupation_handlers_cleaners  occupation_machine_op_inspct  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             1                             0   \n",
       "3                             1                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   occupation_other_service  occupation_priv_house_serv  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   occupation_prof_specialty  occupation_protective_serv  occupation_sales  \\\n",
       "0                          0                           0                 0   \n",
       "1                          0                           0                 0   \n",
       "2                          0                           0                 0   \n",
       "3                          0                           0                 0   \n",
       "4                          1                           0                 0   \n",
       "\n",
       "   occupation_tech_support  occupation_transport_moving  relationship_husband  \\\n",
       "0                        0                            0                     0   \n",
       "1                        0                            0                     1   \n",
       "2                        0                            0                     0   \n",
       "3                        0                            0                     1   \n",
       "4                        0                            0                     0   \n",
       "\n",
       "   relationship_not_in_family  relationship_other_relative  \\\n",
       "0                           1                            0   \n",
       "1                           0                            0   \n",
       "2                           1                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   relationship_own_child  relationship_unmarried  relationship_wife  target  \n",
       "0                       0                       0                  0       0  \n",
       "1                       0                       0                  0       0  \n",
       "2                       0                       0                  0       0  \n",
       "3                       0                       0                  0       0  \n",
       "4                       0                       0                  1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# so that we can see all the columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df_url = 'https://raw.githubusercontent.com/akmand/datasets/master/us_census_income_data_clean_encoded.csv'\n",
    "url_content = requests.get(df_url, verify=False).content\n",
    "df = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n",
    "\n",
    "print(df.shape)\n",
    "df.head().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(n=num_samples, random_state=999).reset_index(drop=True)\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target = df_sample.target.values\n",
    "Data_df = df_sample.drop(columns = 'target')\n",
    "Data_numpy = Data_df.values\n",
    "D_train, D_test, t_train, t_test = train_test_split(Data_numpy, \n",
    "                                                    target, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 41)\n",
      "(2500, 41)\n",
      "(2500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print(D_train.shape)\n",
    "print(D_test.shape)\n",
    "print(t_train.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Assess the cross-validated performance of your DT classifier using the **test** data with all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn import feature_selection as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81756035, 0.86543536, 0.88047532, 0.87261471, 0.91489938])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_full = cross_val_score(estimator=clf,\n",
    "                             X=D_test,\n",
    "                             y=t_test, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "\n",
    "cv_results_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_perf_full = cv_results_full.mean().round(3)\n",
    "cv_perf_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Select the top 10 features via the **F-Score** method using the **train** data.\n",
    "- Evaluate the cross-validated performance of these features using your DT classifier on the **test** data.\n",
    "\n",
    "**NOTE:** For this particular dataset, the F-Score will be \"NaN\" for one of the features due to some technical reasons (related to the nature of the F-distribution). For this reason, when you pass the `fs_fit_fscore.scores_` object in to the `np.argsort()` function, you will need to apply the `np.nan_to_num()` function first. This way, you will convert that \"NaN\" value to zero for a correct result. Specifically, you will need the following line:\n",
    "```Python\n",
    "fs_indices_fscore = np.argsort(np.nan_to_num(fs_fit_fscore.scores_))[::-1][0:num_features]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['marital_status_married_civ_spouse', 'relationship_husband',\n",
       "       'education_num', 'marital_status_never_married',\n",
       "       'relationship_own_child', 'age', 'hours_per_week', 'gender',\n",
       "       'relationship_not_in_family', 'occupation_prof_specialty'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_fit_fscore = fs.SelectKBest(fs.f_classif, k=num_features)\n",
    "fs_fit_fscore.fit_transform(D_train, t_train)\n",
    "fs_indices_fscore = np.argsort(np.nan_to_num(fs_fit_fscore.scores_))[::-1][0:num_features]\n",
    "# Let's see what these top features are\n",
    "best_features_fscore = Data_df.columns[fs_indices_fscore].values\n",
    "best_features_fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_fscore = cross_val_score(estimator=clf,\n",
    "                             X=D_test[:, fs_indices_fscore],\n",
    "                             y=t_test, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_perf_fscore = cv_results_fscore.mean().round(3)\n",
    "cv_perf_fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "- Select the top 10 features using the **Mutual Information** method using the **train** data.\n",
    "- Evaluate the cross-validated performance of these features using your DT classifier on the **test** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['marital_status_married_civ_spouse', 'capital',\n",
       "       'relationship_husband', 'age', 'marital_status_never_married',\n",
       "       'education_num', 'relationship_own_child', 'hours_per_week',\n",
       "       'occupation_exec_managerial', 'relationship_not_in_family'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_fit_mutual_info = fs.SelectKBest(fs.mutual_info_classif, k=num_features)\n",
    "fs_fit_mutual_info.fit_transform(D_train, t_train)\n",
    "fs_indices_mutual_info = np.argsort(fs_fit_mutual_info.scores_)[::-1][0:num_features]\n",
    "# Let's see what these top features are\n",
    "best_features_mutual_info = Data_df.columns[fs_indices_mutual_info].values\n",
    "best_features_mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_mutual_info = cross_val_score(estimator=clf,\n",
    "                             X=D_test[:, fs_indices_mutual_info],\n",
    "                             y=t_test, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_perf_mutual_info = cv_results_mutual_info.mean().round(3)\n",
    "cv_perf_mutual_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "- Select the top 10 features using the **Random Forest Importance** method (with `random_state=999`) with `n_estimators=100` using the **train** data.\n",
    "- Evaluate the cross-validated performance of these features using your DT classifier on the **test** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'education_num', 'capital', 'hours_per_week',\n",
       "       'marital_status_married_civ_spouse', 'relationship_husband',\n",
       "       'marital_status_never_married', 'occupation_prof_specialty',\n",
       "       'occupation_exec_managerial', 'workclass_private'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rfi = RandomForestClassifier(n_estimators=100, random_state=999)\n",
    "model_rfi.fit(D_train, t_train)\n",
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n",
    "# Let's see what these top features are\n",
    "best_features_rfi = Data_df.columns[fs_indices_rfi].values\n",
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_rfi = cross_val_score(estimator=clf,\n",
    "                             X=D_test[:, fs_indices_rfi],\n",
    "                             y=t_test, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_perf_rfi = cv_results_rfi.mean().round(3)\n",
    "cv_perf_rfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Conduct 3 paired t-tests at a 95% significance level: the cross-validated performance with full set of features (using the **test** data) vs. each one of the three FS methods (evaluated again on the **test** data). \n",
    "\n",
    "But first remind yourself the performances of the FS methods by printing the 4 respective `cv_perf_?` variables.\n",
    "\n",
    "Comment on performance of which FS method(s) is (are) statistically different from that of the full set of features. Does FS seem to result in any meaningful dimensionality reduction in this particular case?\n",
    "\n",
    "**Hint:** Any p-value smaller than 0.05 indicates a statistically different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Set of Features (with 41 Features): 0.87\n",
      "Feature Selection with 10 Features:\n",
      "F-Score: 0.855\n",
      "Mutual Information: 0.872\n",
      "RFI: 0.871\n"
     ]
    }
   ],
   "source": [
    "# make sure you are on Python 3.6+ for f-strings to work!\n",
    "print(f'Full Set of Features (with {D_train.shape[1]} Features):', cv_perf_full)\n",
    "print(f'Feature Selection with {num_features} Features:')\n",
    "print('F-Score:', cv_perf_fscore)\n",
    "print('Mutual Information:', cv_perf_mutual_info)\n",
    "print('RFI:', cv_perf_rfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value for Full vs F-Score: 0.262\n",
      "P-Value for Full vs Mutual Information: 0.21\n",
      "P-Value for Full vs RFI: 0.372\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "print('P-Value for Full vs F-Score:', stats.ttest_rel(cv_results_full, cv_results_fscore).pvalue.round(3))\n",
    "print('P-Value for Full vs Mutual Information:', stats.ttest_rel(cv_results_full, cv_results_mutual_info).pvalue.round(3))\n",
    "print('P-Value for Full vs RFI:', stats.ttest_rel(cv_results_full, cv_results_rfi).pvalue.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Re-run your entire notebook with different combinations of different settings and see for yourself if FS is still meaningful. Some suggested changes are as follows:\n",
    "- Change `num_samples` to 10000 or 20000.\n",
    "- Change `num_features` to 5 or 20.\n",
    "- Change `scoring_metric` to 'accuracy' or 'f1'.\n",
    "- Change `max_depth` in DT to 3 or 10.\n",
    "- Try different wrappers, such as KNN with different $k$ and $p$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Feature Selection in a Pipeline\n",
    "\n",
    "Sometimes, we need to determine the number of features. In our example, should it be 10, 20 or 30? One approach is to write a for-loop which iterates a list of number of features. This is not efficient and prone to errors! Luckily we have `Pipeline`! **Note**: F-score seems to cause some issue in `Pipeline`. So, let's try another univariate feature selection method which is $\\chi^{2}$ test: `fs.chiq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=999, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('fs', 'passthrough'),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeClassifier(max_depth=5,\n",
       "                                                               random_state=999))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{'fs': [SelectKBest(k=30,\n",
       "                                             score_func=<function chi2 at 0x000001859F033EE0>)],\n",
       "                          'fs__k': [10, 20, 30, 40]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([\n",
    "    ('fs', 'passthrough'),\n",
    "    ('classifier', clf )\n",
    "])\n",
    "            \n",
    "n_features = [10, 20, 30, 40]\n",
    "param_grid = [\n",
    "    {\n",
    "        'fs': [fs.SelectKBest(fs.chi2)],\n",
    "        'fs__k': n_features,\n",
    "    }    \n",
    "    \n",
    "]\n",
    "grid = GridSearchCV(pipe, \n",
    "                    n_jobs=1, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=cv_method,\n",
    "                    scoring=scoring_metric)\n",
    "grid.fit(D_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the best score and cv_results from the `grid`. Note that the mean scores from the grid correspond to `k=10, 20, 30, 40`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83626222 0.85073711 0.871161   0.87107641]\n",
      "0.8711610021220201\n"
     ]
    }
   ],
   "source": [
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By callling `best_params_`, we can find that 30 features yield the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs': SelectKBest(k=30, score_func=<function chi2 at 0x000001859F033EE0>),\n",
       " 'fs__k': 30}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate cross-validated score by setting estimator to the `grid`. Here is one convenience: we no longer need to slice the test data (`D_train`) as the `grid` contains the information of optimal features obtained from the pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_pip = cross_val_score(estimator=grid,\n",
    "                                 X=D_test,\n",
    "                                 y=t_test, \n",
    "                                 cv=cv_method, \n",
    "                                 scoring=scoring_metric)\n",
    "cv_results_pip = cv_results_pip.mean().round(3)\n",
    "cv_results_pip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Exercise 4, we developed a RandomForest to select the top 10 (`num_features`=10) features and subset the training set before fitting a Decision Tree model (`clf`). We can \"chain\" this process into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_selection',\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(max_features=10,\n",
       "                                                                  random_state=999))),\n",
       "                ('classification',\n",
       "                 DecisionTreeClassifier(max_depth=5, random_state=999))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "  ('feature_selection', fs.SelectFromModel(RandomForestClassifier(n_estimators=100, \n",
    "                                                                  random_state=999,\n",
    "                                                                  max_features=num_features))),\n",
    "  ('classification', clf)\n",
    "])\n",
    "model.fit(D_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
